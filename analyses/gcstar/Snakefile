
# Load useful vars
meta    = {"corn":["cpgplot", "hmm"],
           "rattle":["cpgplot_default", "cpgplot_schield"]}
sp2ref = {"corn":"Pantherophis_guttatus", "rattle": "Crotalus_viridis"}
#species = list(meta.keys())
species = ["corn"]
spots   = ["hotspots", "coldspots"]
outgroup = "Anc0"
slop = 5e3
n_chunks = 100
og2hal = {}
halFile = "/moto/palab/projects/whole-genome_alignments_cactus/HALs/snakes_hm2.hal"

# Branches
with open("misc_files/species_small.txt", "r") as fh:
    branches = [line.strip() for line in fh]

with open("misc_files/rattle2rattle_offset.txt", "r") as fh:
    for line in fh:
        fields = line.split()
        og, og_l, chal, chal_l, offset = fields
        og2hal[og]    = ["", 0]
        og2hal[og][0] = chal
        og2hal[og][1] = int(offset)

# Rules
rule all:
    input: 
        #expand("misc_files/{sp}.{spot}.bed", sp=species, spot=spots),
        #expand("misc_files/{sp}.{spot}.annotated.bed", sp=species, spot=spots),
        #expand(["chunks/{{sp}}.{{spot}}.{}.bed".format(str(x+1).zfill(3)) for x in range(n_chunks)],sp=species, spot=spots),
        #expand("results/{sp}.{spot}.{n}.tab.gz", sp=species, spot=spots, 
        #       n=[str(x+1).zfill(3) for x in range(n_chunks)]),
        #expand("results/{sp}.{spot}.{n}.parsimony.tab.gz", sp=species, spot=spots, 
        #       n=[str(x+1).zfill(3) for x in range(n_chunks)])
        #expand("sub_types/subs/{branch}.{rep}.subtypes.txt", branch=branches, rep=range(20))

rule spots_backrates:
    input: 
        spots = "/moto/palab/users/crh2152/projects/CS_recomb/LDHelmet/Hotspots/Finding_Coldspots/MatchedHotandColdspots.bed"
    output: 
        "misc_files/spots_backrates.tab"
    run: 
        '''
        tail -n+2 {input} \
        | python scripts/extract_backgrounds.py \
        > {output}
        '''
        
rule slop_spots:
    input: 
        spots = "/moto/palab/users/crh2152/projects/CS_recomb/LDHelmet/Hotspots/Finding_Coldspots/MatchedHotandColdspots.bed"
    output: 
        hot = "misc_files/corn.hotspots.annotated.bed",
        cold = "misc_files/corn.coldspots.annotated.bed"
    params:
        gdb = "gsizes/corn.genome",
        slop = int(slop),
        isl1 = "cpgi/corn.cpgplot.bed.gz",
        isl2 = "cpgi/corn.hmm.tss.bed.gz"
    shell: 
        '''
        tail -n+2 {input.spots} \
        | sh ~/bin/add_bed_id.sh \
        | awk -v OFS="\t" '{{print $1,$6,$7,$5,$10,"corn.coldspots"}}' \
        | bedtools sort -i - \
        | bedtools closest -a - -b <(bedtools sort -i {params.isl1}) -d -t first \
        | bedtools closest -a - -b <(bedtools sort -i {params.isl2}) -d -t first \
        | python ~/bin/keep_only_dist.py -i 6 \
        | bedtools slop -i - -g {params.gdb} -b {params.slop} \
        | python ~/bin/add_cl.py -l nan,nan > {output.cold};
        tail -n+2 {input.spots} \
        | cut -f1-3,5 \
        | sh ~/bin/add_bed_id.sh \
        | python ~/bin/add_cl.py -l corn.hotspots \
        | bedtools sort -i - \
        | bedtools closest -a - -b <(bedtools sort -i {params.isl1}) -d -t first \
        | bedtools closest -a - -b <(bedtools sort -i {params.isl2}) -d -t first \
        | python ~/bin/keep_only_dist.py -i 6 \
        | bedtools slop -i - -g {params.gdb} -b {params.slop} \
        | python ~/bin/add_cl.py -l nan,nan > {output.hot}
        '''        

rule divide_and_conquer:
    input: 
        "misc_files/{sp}.{spot}.annotated.bed"
    output: 
        chunks = ["chunks/{{sp}}.{{spot}}.{}.bed".format(str(x+1).zfill(3)) for x in range(n_chunks)]
    resources:
        time = 60,
        cpus = 1
    shell: 
        "split -n l/{n_chunks} -a 3 --numeric-suffixes=1 --additional-suffix=.bed {input} chunks/{wildcards.sp}.{wildcards.spot}."

rule gcstar_parsimony:
    input: 
        "chunks/{sp}.{spot}.{n}.bed"
    output: 
        "results/{sp}.{spot}.{n}.parsimony.tab.gz"
    params:
        halFile = "/moto/palab/projects/whole-genome_alignments_cactus/HALs/snakes_hm2.hal",
        ref = lambda wcs: sp2ref[wcs.sp]
    resources:
        time = 120,
        cpus = 1
    run:
        for spot_file in input:
            with open(spot_file, "r") as fh:
                for line in fh:
                    line = line.strip()
                    fields = line.split() 
                    scaf, start, end, heat, hid, nature, cpg1, cpg2, lift_bp, dist_bp = fields
                    start = int(start)
                    end = int(end)
                    length = int(end) - int(start)                
                        
                    shell("cat misc_files/header_hal2maf.txt "
                           "<(hal2maf {params.halFile} /dev/stdout --refGenome {params.ref} "
                             "--refSequence {scaf} --onlyOrthologs --noDupes --start {start} --length {length}) "
                           "| python scripts/gc_star.py -c {scaf} -s {start} -e {end} -r {params.ref} "
                             "-d {cpg1},{cpg2} -m - -f misc_files/species_ultrasmall.txt -n {nature} -l {lift_bp} -p {dist_bp} "
                             "| python ~/bin/add_comma_list_as_tabs.py -l {heat},{hid} | gzip >> {output}")

# rule gcstar:
#     input: 
#         "chunks/{sp}.{spot}.{n}.bed"
#     output: 
#         "results/{sp}.{spot}.{n}.tab.gz"
#     params:
#         hal = halFile,
#         ref = lambda wcs: sp2ref[wcs.sp]
#     resources:
#         time = 60,
#         cpus = 1
#     run:
#         for spot_file in input:
#             with open(spot_file, "r") as fh:
#                 for line in fh:
#                     line = line.strip()
#                     fields = line.split() 
#                     scaf, start, end, heat, hid, nature, cpg1, cpg2, lift_bp, dist_bp = fields
#                     start = int(start)
#                     end = int(end)
#                     length = int(end) - int(start)                
                        
#                     shell("cat misc_files/header_hal2maf.txt "
#                            "<(hal2maf {params.hal} /dev/stdout --refGenome {params.ref} "
#                              "--refSequence {scaf} --onlyOrthologs --noDupes --start {start} --length {length}) "
#                            "| python scripts/gc_star.py -c {scaf} -s {start} -e {end} -r {params.ref} "
#                              "-d {cpg1},{cpg2} -m - -a {outgroup} -f misc_files/species_small.txt -n {nature} -l {lift_bp} -p {dist_bp} "
#                              "| python ~/bin/add_comma_list_as_tabs.py -l {heat} | gzip >> {output}")

rule generate_random_beds_for_branches:
    input: 
        "gsizes/{branch}.genome"
    output: 
        "sub_types/beds/{branch}.{rep}.bed"
    shell: 
        "bedtools random -g {input} -n 1000 -l 10000 > {output}"

rule get_substitutions_for_branches:
    input: 
        "sub_types/beds/{branch}.{rep}.bed"
    output: 
        "sub_types/subs/{branch}.{rep}.subtypes.txt"
    shell: 
        "halBranchMutations {halFile} {wildcards.branch} --snpFile /dev/stdout "
        "--refTargets {input} | cut -f4 | sed 's/S_//g' | sort | uniq -c | column -t > {output}"

# rule slop_spots:
#     input: 
#         "spots/{sp}.{spot}.bed"
#     output: 
#         "misc_files/{sp}.{spot}.bed"
#     params:
#         gdb = "gsizes/{sp}.genome",
#         slop = int(slop),
#         isl1 = lambda wcs: "cpgi/{}.{}.bed.gz".format(wcs.sp, meta[wcs.sp][0]),
#         isl2 = lambda wcs: "cpgi/{}.{}.bed.gz".format(wcs.sp, meta[wcs.sp][1]),
#         heats = lambda wcs: "spots/{}.heats.bed".format(wcs.sp)
#     shell:
#         "paste <(cut -f1-3 {input}) <(cut -f4 {params.heats}) " 
#         "| awk -v s='{wildcards.sp}.{wildcards.spot}' '{{print $0\"\\t\"$1\":\"$2\"-\"$3\"\\t\"s}}' "
#         "| bedtools sort -i - -g {params.gdb}"
#         "| bedtools closest -a - -b <(bedtools sort -i {params.isl1} -g {params.gdb}) -d -t first -g {params.gdb} "
#         "| bedtools closest -a - -b <(bedtools sort -i {params.isl2} -g {params.gdb}) -d -t first -g {params.gdb} "
#         "| bedtools slop -i - -g {params.gdb} -b {params.slop} "
#         "| python scripts/convert_crotalus_coordinates.py "
#         "| python ~/bin/keep_only_dist.py -i 6 > {output}"

# rule liftover:
#     input: 
#         "misc_files/{sp}.{spot}.bed"
#     output: 
#         psl = "misc_files/{sp}.{spot}.lifted.psl",
#         bed = "misc_files/{sp}.{spot}.annotated.bed"
#     params:
#         sp2 = lambda wcs: [sp for sp in sp2ref if sp!=wcs.sp][0],
#         latin1 = lambda wcs: sp2ref[wcs.sp],
#         latin2 = lambda wcs: sp2ref[[sp for sp in sp2ref if sp!=wcs.sp][0]]
#     shell: 
#         "paste <(cut -f1-3,5- {input} | awk -v OFS=\"\\t\" '{{$2=$2+5000; $3=$3-5000; print $0}}') <(cut -f4 {input})"
#         "| halLiftover {halFile} {params.latin1} stdin {params.latin2} {output.psl} --noDupes --bedType 4 --outPSLWithName;"
#         "awk '{{print $15\"\\t\"$17\"\\t\"$18\"\\t\"$1}}' {output.psl} "
#         "| bedtools sort -i - | bedtools annotate -i - -files misc_files/{params.sp2}.{wildcards.spot}.bed | bedtools sort -i - "
#         "| bedtools closest -a - -b <(bedtools sort -i misc_files/{params.sp2}.{wildcards.spot}.bed | cut -f1-3) -d -t first "
#         "| python ~/bin/keep_only_dist.py -i 5 "
#         "| python scripts/digest_annotate_psl.py -b {wildcards.sp} -s {wildcards.spot} > {output.bed}"

